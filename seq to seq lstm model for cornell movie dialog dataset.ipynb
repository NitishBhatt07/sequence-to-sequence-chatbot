{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d0b6103",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "This is Cornell movie dataset where we have 2 file :\n",
    "1. movie_lines.txt --> this file contains :\n",
    "    - conversation_id(L1045), user(u0), movie(m0), name_of_user(BIANCA), dialog(I want to know)\n",
    "2. movie_conversation.txt --> this file contains :\n",
    "    - the list of conversation of id's which is in movie_lines.txt ['L194','L195','L196','L197']\n",
    "3. we have total 83097 conversations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2759d9db",
   "metadata": {},
   "source": [
    "### for seq 2 seq we need to convert our data to question and answers , where question will be the input to encoders then encoder output the context vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7a0661",
   "metadata": {},
   "source": [
    "# 1. text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61e1f524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening file , there can be some error on lines so we are ignoring,\n",
    "# then we reading all the lines by .read() and .split('\\n') where every new line comes\n",
    "lines = open('data/movie_lines.txt', encoding='utf-8', errors='ignore').read().split('\\n')\n",
    "\n",
    "# for conversation file\n",
    "convers = open('data/movie_conversations.txt', encoding='utf-8', errors='ignore').read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d316017e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the list of list , of conversation id's\n",
    "\n",
    "exchange = []\n",
    "for cover in convers:\n",
    "    exchange.append(cover.split('+++$+++')[-1][2:-1].replace(\"'\",\"\").replace(\",\",\"\").split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ad36926",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['L194', 'L195', 'L196', 'L197'],\n",
       " ['L198', 'L199'],\n",
       " ['L200', 'L201', 'L202', 'L203'],\n",
       " ['L204', 'L205', 'L206'],\n",
       " ['L207', 'L208']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exchange[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b85d36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for movie lines we need to create a dict where key is id and dialog is value\n",
    "dialogs = {}\n",
    "for line in lines:\n",
    "    dialogs[line.split('+++$+++')[0].replace(\" \",\"\")] = line.split('+++$+++')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac19f560",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dialogs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055f0eb8",
   "metadata": {},
   "source": [
    "## Converting to question and answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "952077a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here ith index will be the question and i+1 index is answer\n",
    "# we pick the conversation list and then get the dialog from dialog list\n",
    "\n",
    "questions = []\n",
    "answers = []\n",
    "\n",
    "for conver in exchange:\n",
    "    for i in range(len(conver)-1):\n",
    "        questions.append(dialogs[conver[i]])\n",
    "        answers.append(dialogs[conver[i+1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8256dfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#questions[510:520]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfd5fa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#answers[510:520]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d556fc8",
   "metadata": {},
   "source": [
    "# 2. Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41ce30d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# picking up fixed length question and there respective answer, for fix length\n",
    "sorted_ques = []\n",
    "sorted_ans = []\n",
    "for i in range(len(questions)):\n",
    "    if len(questions[i]) < 13:\n",
    "        sorted_ques.append(questions[i])\n",
    "        sorted_ans.append(answers[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1cbdaae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slicing the answers to 15 words, for fix length\n",
    "for i in range(len(sorted_ans)):\n",
    "    sorted_ans[i] = ' '.join(sorted_ans[i].split()[:13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64ca728a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorted_ques[512:520]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2abe9cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorted_ans[512:520]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea0278be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clening the text\n",
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"i'm\",\"i am\",text)\n",
    "    text = re.sub(r\"i'm\",\"i am\",text)\n",
    "    text = re.sub(r\"\\'ll'\",\"will\",text)\n",
    "    text = re.sub(r\"\\'ve'\",\"have\",text)\n",
    "    text = re.sub(r\"\\'re'\",\"are\",text)\n",
    "    text = re.sub(r\"\\'d'\",\"would\",text)\n",
    "    text = re.sub(r\"[^\\w\\s]\",\"\",text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4148b599",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_ques = []\n",
    "clean_ans = []\n",
    "\n",
    "for line in sorted_ques:\n",
    "    clean_ques.append(clean_text(line))\n",
    "\n",
    "for line in sorted_ans:\n",
    "    clean_ans.append(clean_text(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c1abe2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_ques[512:520]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a7c70c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_ans[512:520]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf3ef14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking sample of 30k\n",
    "clean_ques = clean_ques[:30000]\n",
    "clean_ans = clean_ans[:30000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b932ebc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there can be some word which is rarely used for some time , and also names \n",
    "# so we need to remove these words because they do not impact in model traning that much \n",
    "# and also complex the computation\n",
    "\n",
    "# so we first create a dict if word as key and there count as value\n",
    "\n",
    "word2count = {}\n",
    "\n",
    "# for question\n",
    "for line in clean_ques:\n",
    "    for word in line.split():\n",
    "        if word not in word2count:\n",
    "            word2count[word] = 1\n",
    "        else:\n",
    "            word2count[word] += 1\n",
    "\n",
    "# for answer\n",
    "for line in clean_ans:\n",
    "    for word in line.split():\n",
    "        if word not in word2count:\n",
    "            word2count[word] = 1\n",
    "        else:\n",
    "            word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2fe69791",
   "metadata": {},
   "outputs": [],
   "source": [
    "#word2count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c76419f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the irrelavent word by taking the threshold value\n",
    "\n",
    "# and we need to convert them in integer\n",
    "# so we create a vocabulary : vocubulory is a dict which contains all the words from cleaned ques and ans list\n",
    "# and every word has a unique index\n",
    "\n",
    "thres = 5\n",
    "\n",
    "vocab = {}\n",
    "word_num = 0\n",
    "\n",
    "for word ,count in word2count.items():\n",
    "    if count >= thres:\n",
    "        vocab[word] = word_num\n",
    "        word_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1e1964dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ae480c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can not directly fit the cleaned answer sentence to decoder model \n",
    "# we need to specify the start of string <SOS> and end of string <EOS>\n",
    "\n",
    "for i in range(len(clean_ans)):\n",
    "    clean_ans[i] = '<SOS> '+ clean_ans[i] +' <EOS>' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ea9f68dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_ans[512:520]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "94baec1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# but we also need to append these <SOS> and <EOS> token in vocub dicit because these are also part of data\n",
    "# and model do not expect the string\n",
    "\n",
    "# the <PAD> token is used for padding\n",
    "# padding means if our sent length is 1 , and max sent length is 15 then we add padding to it \n",
    "# we can use pre padding or also use post padding\n",
    "\n",
    "\n",
    "tokens = ['<EOS>','<SOS>','<PAD>','<OUT>']\n",
    "x = len(vocab)\n",
    "for token in tokens:\n",
    "    vocab[token] = x\n",
    "    x += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "244b6bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab['cameron'] = vocab['<PAD>']\n",
    "vocab['<PAD>'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aced52a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inverse dict\n",
    "inv_vocab = {w:v for v, w in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "adf69b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inv_vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338d72af",
   "metadata": {},
   "source": [
    "# 3. Creating  Inputs\n",
    "- Encoder inputs will be the question\n",
    "- Decoder inputs will be the answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b5dc570e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting into numeric values\n",
    "\n",
    "# if word in vocab then we get the index of that word but\n",
    "# if word is not in vocab then we five '<OUT>' to that word \n",
    "    # we consider the threshold value which words are rarely used so they are not in vocab so\n",
    "    # so for those words we append <OUT> tag\n",
    "\n",
    "# encoder input\n",
    "\n",
    "encoder_inp = []\n",
    "for line in clean_ques:\n",
    "    lst = []\n",
    "    for word in line.split():\n",
    "        if word not in vocab:\n",
    "            lst.append(vocab['<OUT>'])\n",
    "        else:\n",
    "            lst.append(vocab[word])\n",
    "    encoder_inp.append(lst)\n",
    "    \n",
    "# decoder input\n",
    "\n",
    "decoder_inp = []\n",
    "for line in clean_ans:\n",
    "    lst = []\n",
    "    for word in line.split():\n",
    "        if word not in vocab:\n",
    "            lst.append(vocab['<OUT>'])\n",
    "        else:\n",
    "            lst.append(vocab[word])\n",
    "    decoder_inp.append(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e941bdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder_inp[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4a5d614b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#decoder_inp[:2]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "07213c57",
   "metadata": {},
   "source": [
    "# vocabulary by one_hot\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "voc_size = 50\n",
    "\n",
    "# encoder input\n",
    "li = []\n",
    "for line in clean_ques[:10]:\n",
    "    temp = []\n",
    "    for word in line.split():\n",
    "        temp.append(one_hot(word,voc_size))\n",
    "    li.append(temp)\n",
    "li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2ecabafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keeping the maxlen of input sequence\n",
    "\n",
    "max_len = 13\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "encoder_inp = pad_sequences(encoder_inp, padding='post', maxlen=max_len, truncating='post')\n",
    "decoder_inp = pad_sequences(decoder_inp, padding='post', maxlen=max_len, truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3b20fe56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(encoder_inp.shape, decoder_inp.shape)\n",
    "#print(encoder_inp[5])\n",
    "#print(decoder_inp[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b1c45974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple working is\n",
    "# 1. encoder takes encoder_inp question and output the context of question\n",
    "# 2. decoder takes decoder_inp answers + context (the output of encoder) \n",
    "# so we need to shift one timestamp ahead from decoder_inp because when it get contaxt and answer then :\n",
    "    # the next word of decoder_inp is prediction of that \n",
    "    # this list is one word further then decoder input because it has all predicted ans i,i+1\n",
    "    # sent = ['this', 'is', 'sent', 'of', 'mine']\n",
    "    # then ['this' + context] = ['is']\n",
    "    # and the list store ['is', 'sent', 'if', 'mine'] , and length is 1 sorter then org one but we do it padding\n",
    "\n",
    "decoder_final_output = []\n",
    "\n",
    "for line in decoder_inp:\n",
    "    decoder_final_output.append(line[1:])\n",
    "\n",
    "decoder_final_output = pad_sequences(decoder_final_output, padding='post', maxlen=max_len, truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "60b24b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#decoder_inp[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0d25fbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#decoder_final_output[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "51efddec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# it convert 2d data to 3d, becasue lstm expect 3d data\n",
    "\n",
    "#from tensorflow.keras.utils import to_categorical\n",
    "#decoder_final_output = to_categorical(decoder_final_output, len(vocab))\n",
    "import numpy as np\n",
    "\n",
    "decoder_final_output = np.array(decoder_final_output.reshape(1,decoder_final_output.shape[0],decoder_final_output.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ba52ea93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 28019, 13)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_final_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b10d32a",
   "metadata": {},
   "source": [
    "# Building Model\n",
    "1. User pass data to => Embedding Layer (used for creating feature representation)\n",
    "2. Then data sent to => LSTM Layer (Encoder) => and genrate Contaxt Vector as o/p\n",
    "3. Then is vecotr send to => Decoder with SOS or any perticular token => predict Next Word as o/p\n",
    "4. This next word is again pass to => Decoder and this predict then next word , and this cycle goes on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "130ac30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, Dropout, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "850ddb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inp = Input(shape=(13, ))\n",
    "decoder_inp = Input(shape=(13, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2f54f315",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(vocab)\n",
    "features = 50\n",
    "input_shape_len = encoder_inp.shape[1]\n",
    "\n",
    "embedding = Embedding(VOCAB_SIZE+1, output_dim=features, input_length=input_shape_len, trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "174f897a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder LSTM \n",
    "\n",
    "encoder_embedded = embedding(encoder_inp)\n",
    "\n",
    "# return_sequence => returns the hidden state at every timestamp\n",
    "# return_state => returns hidden state and cell state at last timestamp\n",
    "\n",
    "encoder_lstm = LSTM(400, return_sequences=True, return_state=True)\n",
    "encoder_op, h, c = encoder_lstm(encoder_embedded)\n",
    "encoder_states = [h,c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "276ff59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder LSTM\n",
    "decoder_embedding = embedding(decoder_inp)\n",
    "\n",
    "decoder_lstm = LSTM(400, return_sequences=True, return_state=True)\n",
    "decoder_op,_,_ = decoder_lstm(decoder_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2cba78b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dense Layer\n",
    "dense = Dense(VOCAB_SIZE, activation='softmax')\n",
    "dense_op = dense(decoder_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc74e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# it takes only two args input data , output data\n",
    "model = Model([encoder_inp,decoder_inp], dense_op)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit([encoder_inp, decoder_inp],\n",
    "          decoder_final_output,\n",
    "          epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62ab2ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
